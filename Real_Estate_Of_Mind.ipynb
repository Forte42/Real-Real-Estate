{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ec45b-1c0b-4e0b-b68d-d8d7f389453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports. Note: You must pip install nasdaqdatalink 1st\n",
    "import os\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from pathlib import Path\n",
    "\n",
    "# For API Calls\n",
    "import nasdaqdatalink\n",
    "# Do we need requests?\n",
    "import requests\n",
    "# For opening zip folder\n",
    "import shutil \n",
    "# For technical analysis\n",
    "import pandas_ta as ta\n",
    "\n",
    "from MCForecastTools import MCSimulation\n",
    "\n",
    "from datetime import datetime\n",
    "import realestate_data as red\n",
    "import realestate_stats as res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9093f0d7-5075-41a1-919f-70da68a4242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linking my API key to .env in the same folder. The key is stored in the folder without any quotations around it \n",
    "nasdaqdatalink.read_key(filename=\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db42cb04-77af-4d32-b836-6ddaad491e54",
   "metadata": {},
   "source": [
    "# 1. Fetching Data \n",
    "In order to analyze the historical real estate and execute Monte Carlo simulations, we will need to fetch the real estate data from Zillow.    We will fetch the following datasets: \n",
    "- Zillow Region Data - This dataset provides a list of states and counties, along with Zillow 'region_id', which is a unique identifier for that specific region. \n",
    "- Zillow Sales Data - This dataset provides a list of historical sales with 'region_id' as the unique id.\n",
    "- Coordinates Data - To display the Zillow sales data on a map, we need to merge it with a dataset that provides coordinates.   However, we couldn't find the county coordinates from Zillow, so we sourced the data from Wikipedia.   We are going to have to merge the data with Zillow based on county and state. \n",
    "\n",
    "## Fetching Zillow Region Data   \n",
    "In this section, we fetch a list region data from Zillow.  The Zillow region data provides a list of states and counties, along with Zillow 'region_id', which is a unique identifier for that specific region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6b9a33-61b7-4862-bd9c-5dd5a90595f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using get_regions to retrieve a list of counties\n",
    "region_df = red.load_zillow_region_data()\n",
    "\n",
    "# Check data for region_df\n",
    "display(region_df.head())\n",
    "display(region_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddc9c9d-61d9-4df0-87d0-0c7033951ef3",
   "metadata": {},
   "source": [
    "## Fetching Zillow Sales Data  \n",
    "In this section, we fetch Zillow sales data in the form of a CSV file.   The Zillow sales data provides a list of historical sales with 'region_id' as the unique id.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f07060-e105-4647-b8a1-242f948e3d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Zillow sales data\n",
    "zillow_data = red.load_zillow_sales_data(region_df)\n",
    "\n",
    "# Check the Zillow sales data\n",
    "display(zillow_data.head())\n",
    "display(zillow_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3417e161-a222-4287-9be9-88bee86cff58",
   "metadata": {},
   "source": [
    "## Fetcing Coordinates Data\n",
    "We want to display our Zillow sales data on a map.  However, we couldn't find the county coordinates from Zillow, so we sourced the data from Wikipedia.   We are going to have to merge the data with Zillow based on county and state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d2a9e4-3475-4ea7-bde1-2bee2582f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in county data with coordinates\n",
    "county_coordinates_df = red.load_county_coordinates()\n",
    "\n",
    "# Check the county coordinates data\n",
    "county_coordinates_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ddc6f8-918a-48c6-9338-4a09f545c955",
   "metadata": {},
   "source": [
    "# 2. Cleaning and Merging Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a44166d-c6c4-4aae-a740-9f07b051c71f",
   "metadata": {},
   "source": [
    "## Merge the Zillow region and sales data\n",
    "Now that we have the Zillow region and sales data, we want to merge the two DataFrames into one DataFrame that contains sales data along with state and county columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e71053-e87e-45f7-8d88-a7c52abe1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the Region dataframe with the Zillow sales data\n",
    "zillow_merge_df = pd.merge(region_df, zillow_data, on=['region_id'])\n",
    "\n",
    "# Rename county_x and state_x so that we can return a clean dataframe\n",
    "zillow_merge_df.rename(\n",
    "        columns={'county_x': 'county', 'state_x': 'state'}, inplace=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "zillow_merge_df = zillow_merge_df[['region_id', 'county', 'state', 'date', 'value']]\n",
    "\n",
    "# Check the merged Zillow data\n",
    "zillow_merge_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ad3909-d77f-49d2-a548-2129cfc24763",
   "metadata": {},
   "source": [
    "## Merge Zillows sales data with coordinates data\n",
    "Now that we have fetched the county coordinates data that includes longitude and latitude, we can merge the data with the Zillow sales data.   This requires us to merge on `county` and `state` columns since the coordinates data does not have a `region_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fd439e-dfdd-4528-9d20-e0f748991a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the Zillow data and county coordinates data.\n",
    "master_df = pd.merge(zillow_merge_df, county_coordinates_df, on=['county', 'state'])\n",
    "\n",
    "master_df['date']=pd.to_datetime(master_df['date'])\n",
    "\n",
    "# Check the master data\n",
    "master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82911426-f791-4ad8-9e22-c3cbe7c0ad22",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Display Historical Data\n",
    "## Display average home sales per county from 1/1/2010 to 12/31/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab676f-978a-43d4-b7d2-185cae02443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_mean_df = res.get_county_df_with_mean(master_df,'2010-01-01', '2021-12-31')\n",
    "# display(county_mean_df.head())\n",
    "\n",
    "# Divide price by 1000 so that it looks better on map.\n",
    "county_mean_df[\"value\"] = county_mean_df[\"value\"] / 1000\n",
    "\n",
    "county_mean_df.hvplot.points(\n",
    "    'longitude',\n",
    "    'latitude',\n",
    "    geo=True,\n",
    "    size='value',\n",
    "    color='value',\n",
    "    tiles='OSM',\n",
    "    height=700,\n",
    "    width=1200, \n",
    "    title='Average home sales per county from 1/1/2010 to 12/31/2021')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06206dd-885e-4a65-8784-abee494052f0",
   "metadata": {},
   "source": [
    "## Display percent change per county from 1/1/2010 to 12/31/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a65879-065b-42a2-a350-56f6e5a8fb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_pct_change_df = res.get_county_df_with_cum_pct_change(master_df,'2010-01-01', '2022-08-01')\n",
    "\n",
    "# Not sure why county_pct_change is missing the longitude and latitude, but I have to add it back :( \n",
    "merge_county_pct_change_df = pd.merge(county_pct_change_df, county_coordinates_df, on=['county', 'state'])\n",
    "\n",
    "\n",
    "# Drop unnecessary columns\n",
    "merge_county_pct_change_df = merge_county_pct_change_df[['region_id', 'county', 'state', 'latitude', 'longitude', 'cum_pct_ch']]\n",
    "\n",
    "# Check the master data\n",
    "display(merge_county_pct_change_df.head())\n",
    "\n",
    "merge_county_pct_change_df.hvplot.points(\n",
    "    'longitude',\n",
    "    'latitude',\n",
    "    geo=True,\n",
    "    size='cum_pct_ch',\n",
    "    color='cum_pct_ch',\n",
    "    tiles='OSM',\n",
    "    height=700,\n",
    "    width=1200, \n",
    "    title='Percent change per county from 1/1/2010 to 12/31/2021')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f540b87-00e8-452a-a808-a0846af13fb6",
   "metadata": {},
   "source": [
    "# 4. The MAC/D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c460f8-d50e-43a6-a38f-7f9a29d7e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a DataFrame using only the columns we are interested in\n",
    "\n",
    "filtered_df = master_df[['date','county','state','value']]\n",
    "\n",
    "filtered_df['county'] = filtered_df['county'] + \", \" + filtered_df['state']\n",
    "drop_cols = ['state']\n",
    "filtered_df = filtered_df.drop(columns=drop_cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14ceedc-8c36-4175-9e3d-2af373309014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figured out the change in number of counties was messing up the charts\n",
    "\n",
    "exploratory_df=filtered_df.groupby('date').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92126f98-3e2e-4a0c-98de-1d6bdec3a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame with summed county markets to represent the entire nation\n",
    "nationwide_df = filtered_df.groupby(filtered_df['date']).agg({'value':'sum'})\n",
    "\n",
    "# Must divide 'values' by number of counties that make up said value so data isn't skewed by county number\n",
    "nationwide_df['avg'] = nationwide_df['value']/exploratory_df['county']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8d6dc4-ba51-47c5-86af-9039ebdf8c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for getting a nationwide MACD indicator using pandas_ta\n",
    "def get_nationwide_macd(fast, slow, signal):\n",
    "    nationwide_macd_df = nationwide_df.ta.macd(close='avg', fast=fast, slow=slow, signal=signal, append=True)\n",
    "    # Making DataFrame look nice\n",
    "    nationwide_macd_df = nationwide_macd_df.rename(columns={f'MACD_{fast}_{slow}_{signal}':'fast_ema',f'MACDh_{fast}_{slow}_{signal}':'signal',f'MACDs_{fast}_{slow}_{signal}':'slow_ema'}).dropna()\n",
    "    # Divide by 1000 so it looks more like a momentum indicator\n",
    "    nationwide_macd_df = nationwide_macd_df/1000\n",
    "    return nationwide_macd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff1b897-1fb9-460b-986a-d41706db4f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use newly defined funtion\n",
    "\n",
    "nationwide_macd_df = get_nationwide_macd(6, 12, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cf3af8-493e-46d7-8594-39384f3ccb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph\n",
    "\n",
    "nationwide_macd_df.hvplot(title='US Housing Market Momentum', ylabel='Momentum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4094e90c-1775-4c1e-82d3-0888eaaa124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show mean housing price in county\n",
    "\n",
    "filtered_df.hvplot(title='Mean Single Famiy Home Price',groupby='county', x='date', yformatter='%.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ecd7e4-59e2-4f4c-a1e4-09d4f4329eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for getting a county-specific MACD indicator using pandas_ta\n",
    "def get_county_macd(fast, slow, signal):\n",
    "    \n",
    "    county_macd_df=filtered_df.copy()\n",
    "    \n",
    "    county_macd_df.ta.macd(close='value', fast=fast, slow=slow, signal=signal, append=True)\n",
    "    \n",
    "    # Making DataFrame look nice\n",
    "    county_macd_df = county_macd_df.rename(columns={f'MACD_{fast}_{slow}_{signal}':'fast_ema',f'MACDh_{fast}_{slow}_{signal}':'signal',f'MACDs_{fast}_{slow}_{signal}':'slow_ema'}).dropna()\n",
    "    \n",
    "    county_macd_df = county_macd_df.drop(columns='value').set_index('date')\n",
    "\n",
    "    county_macd_df[['fast_ema','signal','slow_ema']] = county_macd_df[['fast_ema','signal','slow_ema']]/1000\n",
    "    \n",
    "    return county_macd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25576e2-dd51-4266-ba13-503303a460ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use newly defined function\n",
    "county_macd_df=get_county_macd(6,12,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad48261a-fca4-4f7d-8d0c-6ad3b119731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_macd_df.hvplot(title='MAC/D by County', groupby='county', x='date', ylabel='Momentum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0010060",
   "metadata": {},
   "source": [
    "# 5. Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f60e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = master_df[['date','county','state','value']]\n",
    "filtered_df = filtered_df.sort_values('value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c069295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting county and state columns and replacing with location column which contains county, state\n",
    "# This is necessary because same county names exist in different states. \n",
    "mc_df = filtered_df\n",
    "mc_df['location'] = mc_df['county'] + \", \" + mc_df['state']\n",
    "drop_cols = ['county', 'state']\n",
    "mc_df = mc_df.drop(columns=drop_cols)\n",
    "mc_df.set_index(mc_df['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be2b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting average home value for each location\n",
    "values_df = mc_df.groupby('location', as_index=False)['value'].mean()\n",
    "values_df = values_df.sort_values(by='value')\n",
    "list_of_all_counties = values_df['location'].tolist()\n",
    "list_of_all_counties.sort()\n",
    "highest_df = values_df.tail(3)\n",
    "lowest_df = values_df.head(3)\n",
    "display(highest_df)\n",
    "display(lowest_df)\n",
    "#display(list_of_all_counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b3b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_expensive_counties = highest_df['location'].to_numpy()\n",
    "least_expensive_counties = lowest_df['location'].to_numpy()\n",
    "display(most_expensive_counties)\n",
    "display(least_expensive_counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e3fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_df = mc_df.sort_values(by='date')\n",
    "expensive_dataframe_array = []\n",
    "start_date = '2009-04-30'\n",
    "end_date = '2022-06-30'\n",
    "for group_loc in most_expensive_counties:\n",
    "    df_exp_temp = mc_df.loc[(mc_df['location']==group_loc) & (mc_df['date'] <= end_date) & (mc_df['date'] >= start_date)]\n",
    "    expensive_dataframe_array.append(df_exp_temp.drop('location', axis=1).reset_index())\n",
    "    \n",
    "#dataframe_array\n",
    "expensive_df = pd.concat(expensive_dataframe_array, axis=1, keys=most_expensive_counties)\n",
    "display(mc_df)\n",
    "display(expensive_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f63486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mc_df = mc_df.sort_values(by='date')\n",
    "least_exp_dataframe_array = []\n",
    "start_date = '2009-04-30'\n",
    "end_date = '2022-06-30'\n",
    "for group_loc in least_expensive_counties:\n",
    "    df_temp = mc_df.loc[(mc_df['location']==group_loc) & (mc_df['date'] <= end_date) & (mc_df['date'] >= start_date)]\n",
    "    least_exp_dataframe_array.append(df_temp.drop('location', axis=1).reset_index())\n",
    "    \n",
    "#dataframe_array\n",
    "least_exp_df = pd.concat(least_exp_dataframe_array, axis=1, keys=least_expensive_counties)\n",
    "least_exp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monte Carlo Simulation for 3 most expensive counties\n",
    "mc_expensive_data = MCSimulation(expensive_df, \"\", 1000, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e64b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mc_expensive_data.calc_cumulative_return())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560aeba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_expensive_data.plot_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b23ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_expensive_data.plot_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac3df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_expensive_data.summarize_cumulative_return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e037a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monte Carlo Simulation for 3 least expensive counties\n",
    "mc_least_exp_data = MCSimulation(least_exp_df, \"\", 1000, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a79fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mc_least_exp_data.calc_cumulative_return())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fcea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_least_exp_data.plot_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa97db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_least_exp_data.plot_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384667aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_least_exp_data.summarize_cumulative_return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bbc0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
