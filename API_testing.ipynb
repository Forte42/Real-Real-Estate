{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ec45b-1c0b-4e0b-b68d-d8d7f389453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports. Note: You must pip install nasdaqdatalink 1st\n",
    "import os\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from pathlib import Path\n",
    "\n",
    "# For API Calls\n",
    "import nasdaqdatalink\n",
    "# Do we need requests?\n",
    "import requests\n",
    "# For opening zip folder\n",
    "import shutil \n",
    "# For technical analysis\n",
    "import pandas_ta as ta\n",
    "\n",
    "from MCForecastTools import MCSimulation\n",
    "\n",
    "from datetime import datetime\n",
    "import realestate_data as red\n",
    "import realestate_stats as res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9093f0d7-5075-41a1-919f-70da68a4242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linking my API key to .env in the same folder. The key is stored in the folder without any quotations around it \n",
    "nasdaqdatalink.read_key(filename=\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db42cb04-77af-4d32-b836-6ddaad491e54",
   "metadata": {},
   "source": [
    "# 1. Get the regions data from Zillow REST APIs.   \n",
    "This contains a list of all counties in the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6b9a33-61b7-4862-bd9c-5dd5a90595f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using get_regions to retrieve a list of counties\n",
    "region_df = red.load_zillow_region_data()\n",
    "\n",
    "# Check data for region_df\n",
    "display(region_df.head())\n",
    "display(region_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddc9c9d-61d9-4df0-87d0-0c7033951ef3",
   "metadata": {},
   "source": [
    "# 2. Get the Zillow sales data.  \n",
    "In this example, we read in Zillow sales data in the form of a CSV file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aad324-03d0-4ec9-a026-4e2bb46b2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Zillow sales data. \n",
    "# The actual API call using the SDK.\n",
    "# Instructions can be found here https://data.nasdaq.com/databases/ZILLOW/usage/quickstart/python\n",
    "# Replace 'quandl' w/ 'nasdaqdatalink\n",
    "# Turned into a function to prevent constant re-downloading massive csv\n",
    "\n",
    "def get_zillow_data():\n",
    "    data = nasdaqdatalink.export_table('ZILLOW/DATA', indicator_id='ZSFH', region_id=list(region_df['region_id']),filename='db.zip')\n",
    "    \n",
    "    # Unzipping database from API call\n",
    "    shutil.unpack_archive('db.zip')\n",
    "    return data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f07060-e105-4647-b8a1-242f948e3d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Zillow sales data\n",
    "zillow_data = red.load_zillow_sales_data(region_df)\n",
    "\n",
    "# Check the Zillow sales data\n",
    "display(zillow_data.head())\n",
    "display(zillow_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71295145-437b-46f0-9349-a76f6c422932",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge the Region dataframe with the Zillow sales data\n",
    "zillow_merge_df = pd.merge(region_df, zillow_data, on=['region_id'])\n",
    "\n",
    "zillow_merge_df.rename(\n",
    "        columns={'county_x': 'county', 'state_x': 'state'}, inplace=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "zillow_merge_df = zillow_merge_df[['region_id', 'county', 'state', 'date', 'value']]\n",
    "\n",
    "# Check the merged Zillow data\n",
    "zillow_merge_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3417e161-a222-4287-9be9-88bee86cff58",
   "metadata": {},
   "source": [
    "# 3. Get the county coordinates data.\n",
    "We couldn't find the county coordinates from Zillow, so we sourced the data from Wikipedia.   We are going to have to merge the data with Zillow based on county and state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baed9e0-7b07-484d-84db-33cdea1e278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in county data with coordinates\n",
    "county_coordinates_df = red.load_county_coordinates()\n",
    "\n",
    "# Check the county coordinates data\n",
    "county_coordinates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d2270-bae5-47e0-a8ea-97bce7aa12f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the Zillow data and county coordinates data.\n",
    "master_df = pd.merge(zillow_merge_df, county_coordinates_df, on=['county', 'state'])\n",
    "\n",
    "master_df['date']=pd.to_datetime(master_df['date'])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "master_df = master_df[['region_id', 'county', 'state', 'date', 'value', 'latitude', 'longitude']]\n",
    "\n",
    "# Check the master data\n",
    "master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82911426-f791-4ad8-9e22-c3cbe7c0ad22",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Display Sales Data in a Map\n",
    "## Display average home sales per county from 1/1/2010 to 12/31/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c73013-bdcd-46d9-8648-f056696d79a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "county_mean_df = res.get_county_df_with_mean(master_df,'2010-01-01', '2021-12-31')\n",
    "# display(county_mean_df.head())\n",
    "\n",
    "# Divide price by 1000 so that it looks better on map.\n",
    "county_mean_df[\"value\"] = county_mean_df[\"value\"] / 1000\n",
    "\n",
    "county_mean_df.hvplot.points(\n",
    "    'longitude',\n",
    "    'latitude',\n",
    "    geo=True,\n",
    "    size='value',\n",
    "    color='value',\n",
    "    tiles='OSM',\n",
    "    height=700,\n",
    "    width=1200, \n",
    "    title='Average home sales per county from 1/1/2010 to 12/31/2021')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c0435-5120-49ec-b469-7ce1cd0483b8",
   "metadata": {},
   "source": [
    "# Display percent change per county from 1/1/2010 to 12/31/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d624fdab-50f3-40b9-b4ed-b1672655482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_pct_change_df = res.get_county_df_with_cum_pct_change(master_df,'2010-01-01', '2022-08-01')\n",
    "\n",
    "# Not sure why county_pct_change is missing the longitude and latitude, but I have to add it back :( \n",
    "merge_county_pct_change_df = pd.merge(county_pct_change_df, county_coordinates_df, on=['county', 'state'])\n",
    "\n",
    "\n",
    "# Drop unnecessary columns\n",
    "merge_county_pct_change_df = merge_county_pct_change_df[['region_id', 'county', 'state', 'latitude', 'longitude', 'cum_pct_ch']]\n",
    "\n",
    "# Check the master data\n",
    "display(merge_county_pct_change_df.head())\n",
    "\n",
    "merge_county_pct_change_df.hvplot.points(\n",
    "    'longitude',\n",
    "    'latitude',\n",
    "    geo=True,\n",
    "    size='cum_pct_ch',\n",
    "    color='cum_pct_ch',\n",
    "    tiles='OSM',\n",
    "    height=700,\n",
    "    width=1200, \n",
    "    title='Percent change per county from 1/1/2010 to 12/31/2021')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f540b87-00e8-452a-a808-a0846af13fb6",
   "metadata": {},
   "source": [
    "# The MAC/D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c460f8-d50e-43a6-a38f-7f9a29d7e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a DataFrame using only the columns we are interested in\n",
    "\n",
    "filtered_df = master_df[['date','county','state','value']]\n",
    "\n",
    "filtered_df['county'] = filtered_df['county'] + \", \" + filtered_df['state']\n",
    "drop_cols = ['state']\n",
    "filtered_df = filtered_df.drop(columns=drop_cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14ceedc-8c36-4175-9e3d-2af373309014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figured out the change in number of counties was messing up the charts\n",
    "\n",
    "exploratory_df=filtered_df.groupby('date').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92126f98-3e2e-4a0c-98de-1d6bdec3a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame with summed county markets to represent the entire nation\n",
    "nationwide_df = filtered_df.groupby(filtered_df['date']).agg({'value':'sum'})\n",
    "\n",
    "# Must divide 'values' by number of counties that make up said value so data isn't skewed by county number\n",
    "nationwide_df['avg'] = nationwide_df['value']/exploratory_df['county']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8d6dc4-ba51-47c5-86af-9039ebdf8c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for getting a nationwide MACD indicator using pandas_ta\n",
    "def get_nationwide_macd(fast, slow, signal):\n",
    "    nationwide_macd_df = nationwide_df.ta.macd(close='avg', fast=fast, slow=slow, signal=signal, append=True)\n",
    "    # Making DataFrame look nice\n",
    "    nationwide_macd_df = nationwide_macd_df.rename(columns={f'MACD_{fast}_{slow}_{signal}':'fast_ema',f'MACDh_{fast}_{slow}_{signal}':'signal',f'MACDs_{fast}_{slow}_{signal}':'slow_ema'}).dropna()\n",
    "    # Divide by 1000 so it looks more like a momentum indicator\n",
    "    nationwide_macd_df = nationwide_macd_df/1000\n",
    "    return nationwide_macd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff1b897-1fb9-460b-986a-d41706db4f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use newly defined funtion\n",
    "\n",
    "nationwide_macd_df = get_nationwide_macd(6, 12, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cf3af8-493e-46d7-8594-39384f3ccb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph\n",
    "\n",
    "nationwide_macd_df.hvplot(title='US Housing Market Momentum', ylabel='Momentum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4094e90c-1775-4c1e-82d3-0888eaaa124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show mean housing price in county\n",
    "\n",
    "filtered_df.hvplot(title='Mean Single Famiy Home Price',groupby='county', x='date', yformatter='%.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ecd7e4-59e2-4f4c-a1e4-09d4f4329eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for getting a county-specific MACD indicator using pandas_ta\n",
    "def get_county_macd(fast, slow, signal):\n",
    "    \n",
    "    county_macd_df=filtered_df.copy()\n",
    "    \n",
    "    county_macd_df.ta.macd(close='value', fast=fast, slow=slow, signal=signal, append=True)\n",
    "    \n",
    "    # Making DataFrame look nice\n",
    "    county_macd_df = county_macd_df.rename(columns={f'MACD_{fast}_{slow}_{signal}':'fast_ema',f'MACDh_{fast}_{slow}_{signal}':'signal',f'MACDs_{fast}_{slow}_{signal}':'slow_ema'}).dropna()\n",
    "    \n",
    "    county_macd_df = county_macd_df.drop(columns='value').set_index('date')\n",
    "\n",
    "    county_macd_df[['fast_ema','signal','slow_ema']] = county_macd_df[['fast_ema','signal','slow_ema']]/1000\n",
    "    \n",
    "    return county_macd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25576e2-dd51-4266-ba13-503303a460ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use newly defined function\n",
    "county_macd_df=get_county_macd(6,12,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad48261a-fca4-4f7d-8d0c-6ad3b119731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_macd_df.hvplot(title='MAC/D by County', groupby='county', x='date', ylabel='Momentum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0010060",
   "metadata": {},
   "source": [
    "# Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f60e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = master_df[['date','county','state','value']]\n",
    "filtered_df = filtered_df.sort_values('value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c069295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting county and state columns and replacing with location column which contains county, state\n",
    "# This is necessary because same county names exist in different states. \n",
    "mc_df = filtered_df\n",
    "mc_df['location'] = mc_df['county'] + \", \" + mc_df['state']\n",
    "drop_cols = ['county', 'state']\n",
    "mc_df = mc_df.drop(columns=drop_cols)\n",
    "mc_df.set_index(mc_df['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be2b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting average home value for each location\n",
    "values_df = mc_df.groupby('location', as_index=False)['value'].mean()\n",
    "values_df = values_df.sort_values(by='value')\n",
    "list_of_all_counties = values_df['location'].tolist()\n",
    "list_of_all_counties.sort()\n",
    "highest_df = values_df.tail(3)\n",
    "lowest_df = values_df.head(3)\n",
    "display(highest_df)\n",
    "display(lowest_df)\n",
    "#display(list_of_all_counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b3b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_expensive_counties = highest_df['location'].to_numpy()\n",
    "least_expensive_counties = lowest_df['location'].to_numpy()\n",
    "display(most_expensive_counties)\n",
    "display(least_expensive_counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e3fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_df = mc_df.sort_values(by='date')\n",
    "expensive_dataframe_array = []\n",
    "start_date = '2009-04-30'\n",
    "end_date = '2022-06-30'\n",
    "for group_loc in most_expensive_counties:\n",
    "    df_exp_temp = mc_df.loc[(mc_df['location']==group_loc) & (mc_df['date'] <= end_date) & (mc_df['date'] >= start_date)]\n",
    "    expensive_dataframe_array.append(df_exp_temp.drop('location', axis=1).reset_index())\n",
    "    \n",
    "#dataframe_array\n",
    "expensive_df = pd.concat(expensive_dataframe_array, axis=1, keys=most_expensive_counties)\n",
    "display(mc_df)\n",
    "display(expensive_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f63486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mc_df = mc_df.sort_values(by='date')\n",
    "least_exp_dataframe_array = []\n",
    "start_date = '2009-04-30'\n",
    "end_date = '2022-06-30'\n",
    "for group_loc in least_expensive_counties:\n",
    "    df_temp = mc_df.loc[(mc_df['location']==group_loc) & (mc_df['date'] <= end_date) & (mc_df['date'] >= start_date)]\n",
    "    least_exp_dataframe_array.append(df_temp.drop('location', axis=1).reset_index())\n",
    "    \n",
    "#dataframe_array\n",
    "least_exp_df = pd.concat(least_exp_dataframe_array, axis=1, keys=least_expensive_counties)\n",
    "least_exp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monte Carlo Simulation for 3 most expensive counties\n",
    "mc_expensive_data = MCSimulation(expensive_df, \"\", 1000, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e64b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mc_expensive_data.calc_cumulative_return())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560aeba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_expensive_data.plot_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b23ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_expensive_data.plot_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac3df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_expensive_data.summarize_cumulative_return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e037a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monte Carlo Simulation for 3 least expensive counties\n",
    "mc_least_exp_data = MCSimulation(least_exp_df, \"\", 1000, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a79fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mc_least_exp_data.calc_cumulative_return())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fcea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_least_exp_data.plot_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa97db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_least_exp_data.plot_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384667aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_least_exp_data.summarize_cumulative_return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bbc0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
