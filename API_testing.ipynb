{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ec45b-1c0b-4e0b-b68d-d8d7f389453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports. Note: You must pip install nasdaqdatalink 1st\n",
    "import os\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "# For API Calls\n",
    "import nasdaqdatalink\n",
    "# For opening zip folder\n",
    "import shutil \n",
    "# For technical analysis\n",
    "import pandas_ta as ta\n",
    "\n",
    "from MCForecastTools import MCSimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9093f0d7-5075-41a1-919f-70da68a4242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linking my API key to .env in the same folder. The key is stored in the folder without any quotations around it \n",
    "\n",
    "nasdaqdatalink.read_key(filename=\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5825d4-d5b5-4617-9c2e-18d2ccded14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to retrieve a dataframe of counties, zips, etc\n",
    "def get_regions(regions):\n",
    "    region_df=nasdaqdatalink.get_table('ZILLOW/REGIONS', region_type=regions)  \n",
    "    return region_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db42cb04-77af-4d32-b836-6ddaad491e54",
   "metadata": {},
   "source": [
    "# 1. Get the regions data from Zillow REST APIs.   \n",
    "This contains a list of all counties in the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6b9a33-61b7-4862-bd9c-5dd5a90595f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using get_regions to retrieve a list of counties\n",
    "region_df = get_regions('county')\n",
    "region_df[[\"county\", \"state\"]] = region_df[\"region\"].str.split(';', 1, expand=True)\n",
    "region_df[\"state\"] = region_df[\"state\"].str.split(';', 1, expand=True)[0]\n",
    "\n",
    "#\n",
    "# Clean up regions data\n",
    "# Remove ' County' so that we can match the Zillow data with Wikipedia data.\n",
    "region_df[\"county\"] = region_df[\"county\"].str.replace(\" County\", \"\")\n",
    "\n",
    "# Remove the leading blank space from the 'state' column.\n",
    "region_df[\"state\"] = region_df['state'].str[1:]\n",
    "\n",
    "# Clean up region_id datatype.\n",
    "region_df['region_id']=region_df['region_id'].astype(int)\n",
    "\n",
    "# Check data for region_df\n",
    "display(region_df.head())\n",
    "display(region_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddc9c9d-61d9-4df0-87d0-0c7033951ef3",
   "metadata": {},
   "source": [
    "# 2. Get the Zillow sales data.  \n",
    "In this example, we read in Zillow sales data in the form of a CSV file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aad324-03d0-4ec9-a026-4e2bb46b2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Zillow sales data. \n",
    "# The actual API call using the SDK.\n",
    "# Instructions can be found here https://data.nasdaq.com/databases/ZILLOW/usage/quickstart/python\n",
    "# Replace 'quandl' w/ 'nasdaqdatalink\n",
    "# Turned into a function to prevent constant re-downloading massive csv\n",
    "\n",
    "def get_zillow_data():\n",
    "    data = nasdaqdatalink.export_table('ZILLOW/DATA', indicator_id='ZSFH', region_id=list(region_df['region_id']),filename='db.zip')\n",
    "    \n",
    "    # Unzipping database from API call\n",
    "    shutil.unpack_archive('db.zip')\n",
    "    return data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f07060-e105-4647-b8a1-242f948e3d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in Database\n",
    "zillow_data=pd.read_csv(\n",
    "    Path('ZILLOW_DATA_d5d2ff90eb7172dbde848ea36de12dfe.csv')\n",
    ")\n",
    "\n",
    "# Check the Zillow sales data\n",
    "display(zillow_data.head())\n",
    "display(zillow_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71295145-437b-46f0-9349-a76f6c422932",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge the Region dataframe with the Zillow sales data\n",
    "zillow_merge_df = pd.merge(region_df, zillow_data, on=['region_id'])\n",
    "\n",
    "# Check the merged Zillow data\n",
    "zillow_merge_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3417e161-a222-4287-9be9-88bee86cff58",
   "metadata": {},
   "source": [
    "# 3. Get the county coordinates data.\n",
    "We couldn't find the county coordinates from Zillow, so we sourced the data from Wikipedia.   We are going to have to merge the data with Zillow based on county and state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baed9e0-7b07-484d-84db-33cdea1e278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in county data with coordinates\n",
    "county_coordinates_df=pd.read_csv(\n",
    "    Path('counties_w_coordinates.csv')\n",
    ")\n",
    "\n",
    "# Clean up data.\n",
    "# We need to rename the columns so that we can merge our Zillow data set \n",
    "# with the county coordinates data.   The dataframes will be merged against 'county' and 'state'. \n",
    "county_coordinates_df = county_coordinates_df.rename(columns={\"County\\xa0[2]\" : \"county\"})\n",
    "# county_coordinates_df = county_coordinates_df.rename(columns={\"region\" : \"region\"})\n",
    "county_coordinates_df = county_coordinates_df.rename(columns={\"State\" : \"state\"})\n",
    "\n",
    "# Remove degrees \n",
    "county_coordinates_df[\"Latitude\"] = county_coordinates_df[\"Latitude\"].str.replace(\"°\", \"\")\n",
    "county_coordinates_df[\"Longitude\"] = county_coordinates_df[\"Longitude\"].str.replace(\"°\", \"\")\n",
    "\n",
    "# Remove + sign for Latitude and Longitude\n",
    "county_coordinates_df[\"Latitude\"] = county_coordinates_df[\"Latitude\"].str.replace(\"+\", \"\")\n",
    "county_coordinates_df[\"Longitude\"] = county_coordinates_df[\"Longitude\"].str.replace(\"+\", \"\")\n",
    "\n",
    "# Some of the data uses unicode hyphens which causes problems when trying to convert the Longitude and Latitude to float.\n",
    "county_coordinates_df[\"Latitude\"] = county_coordinates_df[\"Latitude\"].str.replace('\\U00002013', '-')\n",
    "county_coordinates_df[\"Longitude\"] = county_coordinates_df[\"Longitude\"].str.replace('\\U00002013', '-')\n",
    "\n",
    "# Convert Longitude and Latitude to float so we can display on the map. \n",
    "county_coordinates_df[\"Latitude\"] = county_coordinates_df[\"Latitude\"].astype(float)\n",
    "county_coordinates_df[\"Longitude\"] = county_coordinates_df[\"Longitude\"].astype(float)\n",
    "\n",
    "# Check the county coordinates data\n",
    "county_coordinates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d2270-bae5-47e0-a8ea-97bce7aa12f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the Zillow data and county coordinates data.\n",
    "master_df = pd.merge(zillow_merge_df, county_coordinates_df, on=['county', 'state'])\n",
    "\n",
    "master_df['date']=pd.to_datetime(master_df['date'])\n",
    "\n",
    "# Check the master data\n",
    "master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82911426-f791-4ad8-9e22-c3cbe7c0ad22",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Display in a Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1baf4ee-e6ac-4b2e-9754-f116b64cdd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean data by state and county\n",
    "county_df = master_df.groupby([\"state\", \"county\"]).mean()\n",
    "\n",
    "# Divide price by 1000 so that it looks better on map.\n",
    "county_df[\"value\"] = county_df[\"value\"] / 1000\n",
    "\n",
    "# Check data\n",
    "display(county_df.head())\n",
    "display(county_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fc1802-3ec0-46d9-8490-f1222e90cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_df.hvplot.points(\n",
    "    'Longitude',\n",
    "    'Latitude',\n",
    "    geo=True,\n",
    "    size='value',\n",
    "    color='value',\n",
    "    tiles='OSM',\n",
    "    height=700,\n",
    "    width=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f540b87-00e8-452a-a808-a0846af13fb6",
   "metadata": {},
   "source": [
    "# The MAC/D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c460f8-d50e-43a6-a38f-7f9a29d7e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a DataFrame using only the columns we are interested in\n",
    "\n",
    "filtered_df = master_df[['date','county','state','value']]\n",
    "\n",
    "filtered_df['county'] = filtered_df['county'] + \", \" + filtered_df['state']\n",
    "drop_cols = ['state']\n",
    "filtered_df = filtered_df.drop(columns=drop_cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14ceedc-8c36-4175-9e3d-2af373309014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figured out the change in number of counties was messing up the charts\n",
    "\n",
    "exploratory_df=filtered_df.groupby('date').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92126f98-3e2e-4a0c-98de-1d6bdec3a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame with summed county markets to represent the entire nation\n",
    "nationwide_df = filtered_df.groupby(filtered_df['date']).agg({'value':'sum'})\n",
    "\n",
    "# Must divide 'values' by number of counties that make up said value so data isn't skewed by county number\n",
    "nationwide_df['avg'] = nationwide_df['value']/exploratory_df['county']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8d6dc4-ba51-47c5-86af-9039ebdf8c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for getting a nationwide MACD indicator using pandas_ta\n",
    "def get_nationwide_macd(fast, slow, signal):\n",
    "    nationwide_macd_df = nationwide_df.ta.macd(close='avg', fast=fast, slow=slow, signal=signal, append=True)\n",
    "    # Making DataFrame look nice\n",
    "    nationwide_macd_df = nationwide_macd_df.rename(columns={f'MACD_{fast}_{slow}_{signal}':'fast_ema',f'MACDh_{fast}_{slow}_{signal}':'signal',f'MACDs_{fast}_{slow}_{signal}':'slow_ema'}).dropna()\n",
    "    # Divide by 1000 so it looks more like a momentum indicator\n",
    "    nationwide_macd_df = nationwide_macd_df/1000\n",
    "    return nationwide_macd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff1b897-1fb9-460b-986a-d41706db4f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use newly defined funtion\n",
    "\n",
    "nationwide_macd_df = get_nationwide_macd(6, 12, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cf3af8-493e-46d7-8594-39384f3ccb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph\n",
    "\n",
    "nationwide_macd_df.hvplot(title='US Housing Market Momentum', ylabel='Momentum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4094e90c-1775-4c1e-82d3-0888eaaa124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show mean housing price in county\n",
    "\n",
    "filtered_df.hvplot(title='Mean Single Famiy Home Price',groupby='county', x='date', yformatter='%.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ecd7e4-59e2-4f4c-a1e4-09d4f4329eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for getting a county-specific MACD indicator using pandas_ta\n",
    "def get_county_macd(fast, slow, signal):\n",
    "    \n",
    "    county_macd_df=filtered_df.copy()\n",
    "    \n",
    "    county_macd_df.ta.macd(close='value', fast=fast, slow=slow, signal=signal, append=True)\n",
    "    \n",
    "    # Making DataFrame look nice\n",
    "    county_macd_df = county_macd_df.rename(columns={f'MACD_{fast}_{slow}_{signal}':'fast_ema',f'MACDh_{fast}_{slow}_{signal}':'signal',f'MACDs_{fast}_{slow}_{signal}':'slow_ema'}).dropna()\n",
    "    \n",
    "    county_macd_df = county_macd_df.drop(columns='value').set_index('date')\n",
    "\n",
    "    county_macd_df[['fast_ema','signal','slow_ema']] = county_macd_df[['fast_ema','signal','slow_ema']]/1000\n",
    "    \n",
    "    return county_macd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25576e2-dd51-4266-ba13-503303a460ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use newly defined function\n",
    "county_macd_df=get_county_macd(6,12,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad48261a-fca4-4f7d-8d0c-6ad3b119731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_macd_df.hvplot(title='MAC/D by County', groupby='county', x='date', ylabel='Momentum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0010060",
   "metadata": {},
   "source": [
    "# Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f60e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = master_df[['date','county','state','value']]\n",
    "filtered_df = filtered_df.sort_values('value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c069295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting county and state columns and replacing with location column which contains county, state\n",
    "# This is necessary because same county names exist in different states. \n",
    "mc_df = filtered_df\n",
    "mc_df['location'] = mc_df['county'] + \", \" + mc_df['state']\n",
    "drop_cols = ['county', 'state']\n",
    "mc_df = mc_df.drop(columns=drop_cols)\n",
    "mc_df.set_index(mc_df['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be2b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting average home value for each location\n",
    "values_df = mc_df.groupby('location', as_index=False)['value'].mean()\n",
    "values_df = values_df.sort_values(by='value')\n",
    "list_of_all_counties = values_df['location'].tolist()\n",
    "list_of_all_counties.sort()\n",
    "highest_df = values_df.tail(3)\n",
    "lowest_df = values_df.head(3)\n",
    "display(highest_df)\n",
    "display(lowest_df)\n",
    "#display(list_of_all_counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b3b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_expensive_counties = highest_df['location'].to_numpy()\n",
    "least_expensive_counties = lowest_df['location'].to_numpy()\n",
    "display(most_expensive_counties)\n",
    "display(least_expensive_counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e3fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_df = mc_df.sort_values(by='date')\n",
    "expensive_dataframe_array = []\n",
    "start_date = '2009-04-30'\n",
    "end_date = '2022-06-30'\n",
    "for group_loc in most_expensive_counties:\n",
    "    df_exp_temp = mc_df.loc[(mc_df['location']==group_loc) & (mc_df['date'] <= end_date) & (mc_df['date'] >= start_date)]\n",
    "    expensive_dataframe_array.append(df_exp_temp.drop('location', axis=1).reset_index())\n",
    "    \n",
    "#dataframe_array\n",
    "expensive_df = pd.concat(expensive_dataframe_array, axis=1, keys=most_expensive_counties)\n",
    "display(mc_df)\n",
    "display(expensive_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f63486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mc_df = mc_df.sort_values(by='date')\n",
    "least_exp_dataframe_array = []\n",
    "start_date = '2009-04-30'\n",
    "end_date = '2022-06-30'\n",
    "for group_loc in least_expensive_counties:\n",
    "    df_temp = mc_df.loc[(mc_df['location']==group_loc) & (mc_df['date'] <= end_date) & (mc_df['date'] >= start_date)]\n",
    "    least_exp_dataframe_array.append(df_temp.drop('location', axis=1).reset_index())\n",
    "    \n",
    "#dataframe_array\n",
    "least_exp_df = pd.concat(least_exp_dataframe_array, axis=1, keys=least_expensive_counties)\n",
    "least_exp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monte Carlo Simulation for 3 most expensive counties\n",
    "mc_expensive_data = MCSimulation(expensive_df, \"\", 1000, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e64b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mc_expensive_data.calc_cumulative_return())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560aeba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_expensive_data.plot_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b23ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_expensive_data.plot_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac3df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_expensive_data.summarize_cumulative_return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e037a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monte Carlo Simulation for 3 least expensive counties\n",
    "mc_least_exp_data = MCSimulation(least_exp_df, \"\", 1000, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a79fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mc_least_exp_data.calc_cumulative_return())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fcea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_least_exp_data.plot_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa97db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_least_exp_data.plot_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384667aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_least_exp_data.summarize_cumulative_return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bbc0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
